{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from playwright.sync_api import sync_playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anime_season(month: str) -> str:\n",
    "    \"\"\"\n",
    "    This function converts a given month (as a string) into its corresponding season.\n",
    "\n",
    "    Parameters:\n",
    "    - month (str): A string representing the month in the format 'MM'. The valid values are '01' to '12'.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string representing the season. The possible values are 'Winter', 'Spring', 'Summer', 'Fall', or 'Unspecified' if the input month is not within the range of 1 to 12.\n",
    "    \"\"\"\n",
    "    month_num = int(month)\n",
    "    seasons = [\"Winter\", \"Spring\", \"Summer\", \"Fall\"]\n",
    "    return seasons[(month_num - 1) // 3] if 1 <= month_num <= 12 else \"Unspecified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_text(element, default='N/A'):\n",
    "    \"\"\"\n",
    "    This function attempts to extract the text content from a given BeautifulSoup element.\n",
    "\n",
    "    Parameters:\n",
    "    - element (bs4.element.Tag): A BeautifulSoup element representing the HTML element containing the text to be parsed.\n",
    "    - default (str): A default value to return if the element is not found or if the text cannot be parsed.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text content of the element, or the default value if the element is not found or if the text cannot be parsed.\n",
    "    \"\"\"\n",
    "    return element.text.strip() if element else default\n",
    "\n",
    "def safe_int(element, default='N/A'):\n",
    "    \"\"\"\n",
    "    This function attempts to extract an integer value from the text of an element.\n",
    "\n",
    "    Parameters:\n",
    "    - element (bs4.element.Tag): A BeautifulSoup element representing the HTML element containing the text to be parsed.\n",
    "    - default (str): A default value to return if the element is not found or if the text cannot be parsed as an integer.\n",
    "\n",
    "    Returns:\n",
    "    - int or str: An integer value extracted from the text of the element, or the default value if the text cannot be parsed as an integer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(element.text.strip().replace(',', '')) if element else default\n",
    "    except ValueError:\n",
    "        return default\n",
    "\n",
    "def safe_float(element, default='N/A'):\n",
    "    \"\"\"\n",
    "    This function attempts to extract a float value from the text of an element.\n",
    "\n",
    "    Parameters:\n",
    "    - element (bs4.element.Tag): A BeautifulSoup element representing the HTML element containing the text to be parsed.\n",
    "    - default (str): A default value to return if the element is not found or if the text cannot be parsed as a float.\n",
    "\n",
    "    Returns:\n",
    "    - float or str: A float value extracted from the text of the element, or the default value if the text cannot be parsed as a float.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(element.text.strip()) if element else default\n",
    "    except ValueError:\n",
    "        return default\n",
    "\n",
    "def scrape_anime_data(anime_item) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    This function extracts and returns the scraped data of an anime from the given anime_item.\n",
    "   \n",
    "    Parameters:\n",
    "    - anime_item (bs4.element.Tag): A BeautifulSoup element representing the anime item to scrape.\n",
    "\n",
    "    Returns:\n",
    "    - dict[str, str]: A dictionary containing the scraped data of the anime, with keys representing the data categories and values representing the corresponding data.\n",
    "\n",
    "    The dictionary contains the following keys and their respective data categories:\n",
    "    - 'Title': The title of the anime.\n",
    "    - 'Voters': The number of voters for the anime.\n",
    "    - 'Avg Score': The average score of the anime.\n",
    "    - 'Start Date': The start date of the anime.\n",
    "    - 'Status': The status of the anime (either 'finished' or 'airing').\n",
    "    - 'Studio': The studio that produced the anime.\n",
    "    - 'Genres': A comma-separated list of genres for the anime.\n",
    "    - 'Media': The type of media the anime belongs to.\n",
    "    - 'Eps': The number of episodes in the anime.\n",
    "    - 'Duration': The duration of each episode in the anime.\n",
    "    - 'Synopsis': The synopsis or summary of the anime.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'Title': safe_text(anime_item.find('a', class_='link-title')),\n",
    "        'Voters': safe_int(anime_item.find('div', class_='scormem-item member')),\n",
    "        'Avg Score': safe_float(anime_item.find('div', title='Score')),\n",
    "        'Start Date': safe_text(anime_item.find('span', class_='item')),\n",
    "        'Status': safe_text(\n",
    "            anime_item.find('span', class_='item finished') or anime_item.find('span', class_='item airing')),\n",
    "        'Studio': safe_text(anime_item.find('span', class_='producer')),\n",
    "        'Genres': ', '.join(genre.text.strip() for genre in anime_item.find_all('span', class_='genre')) or 'N/A',\n",
    "        'Media': safe_text(anime_item.find('span', class_='type')),\n",
    "        'Eps': safe_text(anime_item.find('span', class_='eps')).split()[0],\n",
    "        'Duration': safe_text(anime_item.find('span', class_='duration')).split()[0],\n",
    "        'Synopsis': safe_text(anime_item.find('p', class_='preline'))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_scrape(url: str, page_limit: int) -> list[dict[str, str]]:\n",
    "    \"\"\"Fetch and scrape anime data from the given URL.\"\"\"\n",
    "    all_data = []\n",
    "    for page_num in range(1, page_limit + 1):\n",
    "        page_url = f'{url}?page={page_num}'\n",
    "        print(f'Scraping {page_url}...')\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(page_url)\n",
    "            response.raise_for_status()  # Raise an error for bad responses\n",
    "            soup = bs(response.text, 'html.parser')\n",
    "\n",
    "            anime_list = soup.find_all('div', class_='anime-item')  # Update with the actual class for anime items\n",
    "            for anime_item in anime_list:\n",
    "                anime_data = scrape_anime_data(anime_item)\n",
    "                all_data.append(anime_data)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'Error fetching {page_url}: {e}')\n",
    "            break\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeler(date: str, data: list[dict[str, str]]) -> None:\n",
    "    \"\"\"\n",
    "    Processes and saves anime data to a CSV file.\n",
    "\n",
    "    -----\n",
    "    Parameters:\n",
    "    - date (str): The date string used to name the CSV file.\n",
    "    - data (List[Dict[str, str]]): A list of dictionaries containing anime data.\n",
    "\n",
    "    -----\n",
    "    The function converts the list of dictionaries to a DataFrame, removes duplicate entries,\n",
    "    and saves the DataFrame to a CSV file in the 'data/processed' directory.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    file_path = 'data/raw'    \n",
    "    df.to_csv(f'../../{file_path}/AnimeData_{date}.csv', index=False)\n",
    "    print(f'Data saved to {file_path}/AnimeData_{date}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://myanimelist.net/anime/genre/1/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/2/?page=1...\n",
      "Data saved to data/raw/AnimeData_270724.csv\n"
     ]
    }
   ],
   "source": [
    "date = datetime.now().strftime('%d%m%y')\n",
    "\n",
    "# EXTRACT AND TRANSFORM\n",
    "url_list = [   \n",
    "    'https://myanimelist.net/anime/genre/1/',  # Action\n",
    "    'https://myanimelist.net/anime/genre/2/',  # Adventure\n",
    "    'https://myanimelist.net/anime/genre/5/',  # Avant Garde\n",
    "    'https://myanimelist.net/anime/genre/4/',  # Comedy\n",
    "    'https://myanimelist.net/anime/genre/8/',  # Drama\n",
    "    'https://myanimelist.net/anime/genre/10/', # Fantasy\n",
    "    'https://myanimelist.net/anime/genre/47/', # Gourmet\n",
    "    'https://myanimelist.net/anime/genre/14/', # Horror\n",
    "    'https://myanimelist.net/anime/genre/7/',  # Mystery\n",
    "    'https://myanimelist.net/anime/genre/22/', # Romance\n",
    "    'https://myanimelist.net/anime/genre/24/', # Sci-fi\n",
    "    'https://myanimelist.net/anime/genre/36/', # Slice-of-life\n",
    "    'https://myanimelist.net/anime/genre/30/', # Sport\n",
    "    'https://myanimelist.net/anime/genre/37/', # Supernatural\n",
    "    'https://myanimelist.net/anime/genre/41/'  # Suspense\n",
    "]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_data = []\n",
    "    for url in url_list:\n",
    "        all_data.extend(fetch_and_scrape(url, 1))\n",
    "    \n",
    "    modeler(date, all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
