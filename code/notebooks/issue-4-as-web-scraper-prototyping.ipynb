{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anime_season(month: str) -> str:\n",
    "    \"\"\"\n",
    "    This function converts a given month (as a string) into its corresponding season.\n",
    "\n",
    "    Parameters:\n",
    "    - month (str): A string representing the month in the format 'MM'. The valid values are '01' to '12'.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string representing the season. The possible values are 'Winter', 'Spring', 'Summer', 'Fall', or 'Unspecified' if the input month is not within the range of 1 to 12.\n",
    "    \"\"\"\n",
    "    month_num = int(month)\n",
    "    seasons = [\"Winter\", \"Spring\", \"Summer\", \"Fall\"]\n",
    "    return seasons[(month_num - 1) // 3] if 1 <= month_num <= 12 else \"Unspecified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_text(element, default='N/A'):\n",
    "    \"\"\"\n",
    "    This function attempts to extract the text content from a given BeautifulSoup element.\n",
    "    \n",
    "    Parameters:\n",
    "    - element (bs4.element.Tag): A BeautifulSoup element representing the HTML element containing the text to be parsed.\n",
    "    - default (str): A default value to return if the element is not found or if the text cannot be parsed.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The text content of the element, or the default value if the element is not found or if the text cannot be parsed.\n",
    "    \"\"\"\n",
    "    return element.text.strip() if element else default\n",
    "\n",
    "def safe_int(element, default='N/A'):\n",
    "    \"\"\"\n",
    "    This function attempts to extract an integer value from the text of an element.\n",
    "    \n",
    "    Parameters:\n",
    "    - element (bs4.element.Tag): A BeautifulSoup element representing the HTML element containing the text to be parsed.\n",
    "    - default (str): A default value to return if the element is not found or if the text cannot be parsed as an integer.\n",
    "    \n",
    "    Returns:\n",
    "    - int or str: An integer value extracted from the text of the element, or the default value if the text cannot be parsed as an integer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(element.text.strip().replace(',', '')) if element else default\n",
    "    except ValueError:\n",
    "        return default\n",
    "\n",
    "def safe_float(element, default='N/A'):\n",
    "    \"\"\"\n",
    "    This function attempts to extract a float value from the text of an element.\n",
    "    \n",
    "    Parameters:\n",
    "    - element (bs4.element.Tag): A BeautifulSoup element representing the HTML element containing the text to be parsed.\n",
    "    - default (str): A default value to return if the element is not found or if the text cannot be parsed as a float.\n",
    "    \n",
    "    Returns:\n",
    "    - float or str: A float value extracted from the text of the element, or the default value if the text cannot be parsed as a float.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(element.text.strip()) if element else default\n",
    "    except ValueError:\n",
    "        return default\n",
    "\n",
    "def scrape_anime_data(anime_item) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extract data from the HTML content of an anime item.\n",
    "    \n",
    "    Parameters:\n",
    "    - anime_item (BeautifulSoup): A BeautifulSoup object containing the HTML of an anime item.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary with the number of episodes and the release year.\n",
    "    \"\"\"\n",
    "    soup = bs(anime_item, 'html.parser')\n",
    "    \n",
    "    start_date_text = soup.find('span', class_='item')\n",
    "    release_year = start_date_text.text.strip().split(', ')[-1] if start_date_text else 'N/A'\n",
    "    \n",
    "    info_div = soup.find('div', class_='info')\n",
    "    if info_div:\n",
    "        eps_text = info_div.get_text()\n",
    "        match = re.search(r'(\\d+)\\s*eps', eps_text)\n",
    "        number_of_episodes = match.group(1) if match else 'N/A'\n",
    "    else:\n",
    "        number_of_episodes = 'N/A'\n",
    "    \n",
    "    status_span = soup.find('span', class_='item finished') or soup.find('span', class_='item airing')\n",
    "    status = status_span.text.strip() if status_span else 'N/A'\n",
    "    \n",
    "    genres_div = soup.find('div', class_='genres-inner js-genre-inner')\n",
    "    genres = ', '.join([genre.find('a').text.strip() for genre in genres_div.find_all('span', class_='genre')]) if genres_div else 'N/A'\n",
    "    \n",
    "    properties_div = soup.find('div', class_='properties')\n",
    "    \n",
    "    def extract_property(caption):\n",
    "        \"\"\"Helper function to extract property values based on the caption\"\"\"\n",
    "        if not properties_div:\n",
    "            return 'N/A'\n",
    "        property_divs = properties_div.find_all('div', class_='property')\n",
    "        for div in property_divs:\n",
    "            caption_span = div.find('span', class_='caption')\n",
    "            if caption_span and caption_span.text.strip() == caption:\n",
    "                item_spans = div.find_all('span', class_='item')\n",
    "                return ', '.join(item.get_text(strip=True) for item in item_spans) if item_spans else 'N/A'\n",
    "        return 'N/A'\n",
    "    \n",
    "    studio = extract_property('Studio')\n",
    "    source = extract_property('Source')\n",
    "    demographic = extract_property('Demographic')\n",
    "    \n",
    "    # Extract themes using regex pattern for URLs\n",
    "    themes = 'N/A'\n",
    "    if properties_div:\n",
    "        themes_div = properties_div.find('div', class_='property')\n",
    "        if themes_div:\n",
    "            themes_html = str(themes_div)\n",
    "            theme_matches = re.findall(\n",
    "                r'<span class=\"item\"><a href=\"/anime/genre/\\d+/[^\"]*\" title=\"[^\"]*\">([^<]*)</a></span>', themes_html)\n",
    "            themes = ', '.join(theme_matches) if theme_matches else 'N/A'\n",
    "    \n",
    "    # Extract the rating\n",
    "    rating = safe_float(soup.find('div', class_='scormem-item score score-label score-8'), 'N/A')\n",
    "    \n",
    "    # Extract the voter count\n",
    "    voters = safe_int(soup.find('div', class_='scormem-item member'), 'N/A')\n",
    "    \n",
    "    # Extract synopsis\n",
    "    synopsis = safe_text(soup.find('div', class_='synopsis js-synopsis').find('p', class_='preline'), 'N/A')\n",
    "    \n",
    "    return {\n",
    "        'Episodes': number_of_episodes,\n",
    "        'Release Year': release_year,\n",
    "        'Status': status,\n",
    "        'Genres': genres,\n",
    "        'Studio': studio,\n",
    "        'Source': source,\n",
    "        'Demographic': demographic,\n",
    "        'Themes': themes,\n",
    "        'Synopsis': synopsis,\n",
    "        'Voters': voters,\n",
    "        'Rating': rating,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_scrape(url: str, page_limit: int) -> list[dict[str, str]]:\n",
    "    \"\"\"Fetch and scrape anime data from the given URL.\"\"\"\n",
    "    all_data = []\n",
    "    for page_num in range(1, page_limit + 1):\n",
    "        page_url = f'{url}?page={page_num}'\n",
    "        print(f'Scraping {page_url}...')\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(page_url)\n",
    "            response.raise_for_status()  # Raise an error for bad responses\n",
    "            soup = bs(response.text, 'html.parser')\n",
    "\n",
    "            anime_list = soup.find_all('div', class_='anime-item')  # Update with the actual class for anime items\n",
    "            for anime_item in anime_list:\n",
    "                anime_data = scrape_anime_data(anime_item)\n",
    "                all_data.append(anime_data)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'Error fetching {page_url}: {e}')\n",
    "            break\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeler(date: str, data: list[dict[str, str]]) -> None:\n",
    "    \"\"\"\n",
    "    Processes and saves anime data to a CSV file.\n",
    "\n",
    "    -----\n",
    "    Parameters:\n",
    "    - date (str): The date string used to name the CSV file.\n",
    "    - data (List[Dict[str, str]]): A list of dictionaries containing anime data.\n",
    "\n",
    "    -----\n",
    "    The function converts the list of dictionaries to a DataFrame, removes duplicate entries,\n",
    "    and saves the DataFrame to a CSV file in the 'data/processed' directory.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    file_path = 'data/raw'    \n",
    "    df.to_csv(f'../../{file_path}/AnimeData_{date}.csv', index=False)\n",
    "    print(f'Data saved to {file_path}/AnimeData_{date}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://myanimelist.net/anime/genre/1/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/2/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/5/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/4/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/8/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/10/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/47/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/14/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/7/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/22/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/24/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/36/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/30/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/37/?page=1...\n",
      "Scraping https://myanimelist.net/anime/genre/41/?page=1...\n",
      "Data saved to data/raw/AnimeData_280724.csv\n"
     ]
    }
   ],
   "source": [
    "date = datetime.now().strftime('%d%m%y')\n",
    "\n",
    "# EXTRACT AND TRANSFORM\n",
    "url_list = [   \n",
    "    'https://myanimelist.net/anime/genre/1/',  # Action\n",
    "    'https://myanimelist.net/anime/genre/2/',  # Adventure\n",
    "    'https://myanimelist.net/anime/genre/5/',  # Avant Garde\n",
    "    'https://myanimelist.net/anime/genre/4/',  # Comedy\n",
    "    'https://myanimelist.net/anime/genre/8/',  # Drama\n",
    "    'https://myanimelist.net/anime/genre/10/', # Fantasy\n",
    "    'https://myanimelist.net/anime/genre/47/', # Gourmet\n",
    "    'https://myanimelist.net/anime/genre/14/', # Horror\n",
    "    'https://myanimelist.net/anime/genre/7/',  # Mystery\n",
    "    'https://myanimelist.net/anime/genre/22/', # Romance\n",
    "    'https://myanimelist.net/anime/genre/24/', # Sci-fi\n",
    "    'https://myanimelist.net/anime/genre/36/', # Slice-of-life\n",
    "    'https://myanimelist.net/anime/genre/30/', # Sport\n",
    "    'https://myanimelist.net/anime/genre/37/', # Supernatural\n",
    "    'https://myanimelist.net/anime/genre/41/'  # Suspense\n",
    "]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_data = []\n",
    "    for url in url_list:\n",
    "        all_data.extend(fetch_and_scrape(url, 1))\n",
    "    \n",
    "    modeler(date, all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correct ones\n",
    "- status_span = soup.find('span', class_='item finished') or soup.find('span', class_='item airing')\n",
    "status = status_span.text.strip() if status_span else 'N/A'\n",
    "\n",
    "-  info_div = soup.find('div', class_='info')\n",
    "    if info_div:\n",
    "        eps_text = info_div.get_text()\n",
    "        match = re.search(r'(\\d+)\\s*eps', eps_text)\n",
    "        number_of_episodes = match.group(1) if match else 'N/A'\n",
    "    else:\n",
    "        number_of_episodes = 'N/A'\n",
    "\n",
    "-   start_date_text = soup.find('span', class_='item')\n",
    "    release_year = start_date_text.text.strip().split(', ')[-1] if start_date_text else 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = '''\n",
    "<div class=\"prodsrc\">\n",
    "      <div class=\"video\"><a href=\"https://myanimelist.net/anime/16498/Shingeki_no_Kyojin/video\" class=\"ga-click\" title=\"Watch Episode Video\"><i class=\"malicon malicon-movie-episode\"></i></a>      </div>\n",
    "      <div class=\"info\"><span class=\"item\">TV, 2013</span><span class=\"item finished\">Finished</span><span class=\"item\">\n",
    "          <span>25 eps</span>,\n",
    "          <span>24 min </span>\n",
    "        </span>\n",
    "      </div>\n",
    "      <div class=\"broadcast\"><a href=\"javascript:void(0)\" onclick=\"return false;\" class=\"js-broadcast-button ga-click\" data-title=\"Shingeki no Kyojin\" data-subtitle=\"Attack on Titan\" data-raw=\"{&quot;data&quot;:[{&quot;platform&quot;:{&quot;id&quot;:1,&quot;name&quot;:&quot;Crunchyroll&quot;,&quot;icon&quot;:&quot;crunchyroll&quot;,&quot;type&quot;:1},&quot;available&quot;:false,&quot;url&quot;:&quot;http:\\/\\/www.crunchyroll.com\\/series-280312&quot;},{&quot;platform&quot;:{&quot;id&quot;:2,&quot;name&quot;:&quot;Netflix&quot;,&quot;icon&quot;:&quot;netflix&quot;,&quot;type&quot;:1},&quot;available&quot;:false,&quot;url&quot;:&quot;https:\\/\\/www.netflix.com\\/title\\/70299043&quot;},{&quot;platform&quot;:{&quot;id&quot;:28,&quot;name&quot;:&quot;Shahid&quot;,&quot;icon&quot;:&quot;shahid&quot;,&quot;type&quot;:2},&quot;available&quot;:false,&quot;url&quot;:&quot;https:\\/\\/shahid.mbc.net\\/en\\/series\\/Attack-On-Titan\\/series-922170&quot;}],&quot;count&quot;:{&quot;available&quot;:0,&quot;typicals&quot;:2,&quot;others&quot;:1,&quot;total&quot;:3}}\" data-ga-click-type=\"broadcast-tile-streaming-icon\" data-ga-click-param=\"aid:16498\"><i class=\"malicon malicon-streaming-slash\"></i></a></div>\n",
    "    </div>\n",
    "    \n",
    "<div class=\"genres-inner js-genre-inner\"><span class=\"genre\">\n",
    "        <a href=\"/anime/genre/1/Action\" title=\"Action\">Action</a>\n",
    "      </span><span class=\"genre\">\n",
    "        <a href=\"/anime/genre/46/Award_Winning\" title=\"Award Winning\">Award Winning</a>\n",
    "      </span><span class=\"genre\">\n",
    "        <a href=\"/anime/genre/8/Drama\" title=\"Drama\">Drama</a>\n",
    "      </span><span class=\"genre\">\n",
    "        <a href=\"/anime/genre/41/Suspense\" title=\"Suspense\">Suspense</a>\n",
    "      </span></div>\n",
    "      \n",
    "<div class=\"properties\">\n",
    "      <div class=\"property\">\n",
    "        <span class=\"caption\">Studio</span><span class=\"item\"><a href=\"/anime/producer/858/Wit_Studio\" title=\"Wit Studio\">Wit Studio</a></span></div>\n",
    "      <div class=\"property\">\n",
    "        <span class=\"caption\">Source</span><span class=\"item\">Manga</span>\n",
    "      </div><div class=\"property\">\n",
    "        <span class=\"caption\">Themes</span><span class=\"item\"><a href=\"/anime/genre/58/Gore\" title=\"Gore\">Gore</a></span><span class=\"item\"><a href=\"/anime/genre/38/Military\" title=\"Military\">Military</a></span><span class=\"item\"><a href=\"/anime/genre/76/Survival\" title=\"Survival\">Survival</a></span></div><div class=\"property\">\n",
    "        <span class=\"caption\">Demographic</span><span class=\"item\"><a href=\"/anime/genre/27/Shounen\" title=\"Shounen\">Shounen</a></span></div></div>\n",
    "        \n",
    "<div class=\"synopsis js-synopsis\">\n",
    "    <p class=\"preline\">Centuries ago, mankind was slaughtered to near extinction by monstrous humanoid creatures called Titans, forcing humans to hide in fear behind enormous concentric walls. What makes these giants truly terrifying is that their taste for human flesh is not born out of hunger but what appears to be out of pleasure. To ensure their survival, the remnants of humanity began living within defensive barriers, resulting in one hundred years without a single titan encounter. However, that fragile calm is soon shattered when a colossal Titan manages to breach the supposedly impregnable outer wall, reigniting the fight for survival against the man-eating abominations.\n",
    "\n",
    "After witnessing a horrific personal loss at the hands of the invading creatures, Eren Yeager dedicates his life to their eradication by enlisting into the Survey Corps, an elite military unit that combats the merciless humanoids outside the protection of the walls. Eren, his adopted sister Mikasa Ackerman, and his childhood friend Armin Arlert join the brutal war against the Titans and race to discover a way of defeating them before the last walls are breached.\n",
    "\n",
    "[Written by MAL Rewrite]</p>\n",
    "    <button class=\"js-toggle-text toggle-text\" style=\"display: block; margin: 0 auto; background: none; border: none;\">\n",
    "      <i class=\"fa-solid fa-angle-down\" style=\"pointer-events: none;\"></i>\n",
    "    </button>\n",
    "\n",
    "    <div class=\"properties\">\n",
    "      <div class=\"property\">\n",
    "        <span class=\"caption\">Studio</span><span class=\"item\"><a href=\"/anime/producer/858/Wit_Studio\" title=\"Wit Studio\">Wit Studio</a></span></div>\n",
    "      <div class=\"property\">\n",
    "        <span class=\"caption\">Source</span><span class=\"item\">Manga</span>\n",
    "      </div><div class=\"property\">\n",
    "        <span class=\"caption\">Themes</span><span class=\"item\"><a href=\"/anime/genre/58/Gore\" title=\"Gore\">Gore</a></span><span class=\"item\"><a href=\"/anime/genre/38/Military\" title=\"Military\">Military</a></span><span class=\"item\"><a href=\"/anime/genre/76/Survival\" title=\"Survival\">Survival</a></span></div><div class=\"property\">\n",
    "        <span class=\"caption\">Demographic</span><span class=\"item\"><a href=\"/anime/genre/27/Shounen\" title=\"Shounen\">Shounen</a></span></div></div>\n",
    "  </div>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Episodes': '25',\n",
       " 'Release Year': '2013',\n",
       " 'Status': 'Finished',\n",
       " 'Genres': 'Action, Award Winning, Drama, Suspense',\n",
       " 'Studio': 'Wit Studio',\n",
       " 'Source': 'Manga',\n",
       " 'Demographic': 'Shounen',\n",
       " 'Themes': 'N/A',\n",
       " 'Synopsis': 'Centuries ago, mankind was slaughtered to near extinction by monstrous humanoid creatures called Titans, forcing humans to hide in fear behind enormous concentric walls. What makes these giants truly terrifying is that their taste for human flesh is not born out of hunger but what appears to be out of pleasure. To ensure their survival, the remnants of humanity began living within defensive barriers, resulting in one hundred years without a single titan encounter. However, that fragile calm is soon shattered when a colossal Titan manages to breach the supposedly impregnable outer wall, reigniting the fight for survival against the man-eating abominations.\\n\\nAfter witnessing a horrific personal loss at the hands of the invading creatures, Eren Yeager dedicates his life to their eradication by enlisting into the Survey Corps, an elite military unit that combats the merciless humanoids outside the protection of the walls. Eren, his adopted sister Mikasa Ackerman, and his childhood friend Armin Arlert join the brutal war against the Titans and race to discover a way of defeating them before the last walls are breached.\\n\\n[Written by MAL Rewrite]',\n",
       " 'Voters': 'N/A',\n",
       " 'Rating': 'N/A'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_anime_data(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
