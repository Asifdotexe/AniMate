{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from playwright.sync_api import sync_playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anime_season(month: str) -> str:\n",
    "    \"\"\"\n",
    "    This function takes a month as input and returns the corresponding season.\n",
    "    \n",
    "    Reason for including this:\n",
    "    Users might want recommendations for anime from a particular season, like \n",
    "    \"I want to watch anime from the latest season\" or \n",
    "    \"Show me the best anime from Fall 2022.\"\n",
    "    ----- \n",
    "    Parameters:\n",
    "    - month (str): The month for which the season needs to be determined.\n",
    "    -----\n",
    "    Returns:\n",
    "    - str: The season corresponding to the input month. If the month is not recognized, it returns 'Unspecified'.\n",
    "    -----\n",
    "    Example:\n",
    "    >>> anime_season('3')\n",
    "    'Winter'\n",
    "    >>> anime_season('7')\n",
    "    'Summer'\n",
    "    >>> anime_season('13')\n",
    "    'Unspecified'\n",
    "    \"\"\"\n",
    "    # Define a dictionary mapping months to seasons\n",
    "    month_to_season = {\n",
    "        1: 'Winter', 2: 'Winter', 3: 'Winter',\n",
    "        4: 'Spring', 5: 'Spring', 6: 'Spring',\n",
    "        7: 'Summer', 8: 'Summer', 9: 'Summer',\n",
    "        10: 'Fall', 11: 'Fall', 12: 'Fall'\n",
    "    }\n",
    "\n",
    "    # Convert month to integer and get the season\n",
    "    try:\n",
    "        month_num = int(month)\n",
    "        return month_to_season.get(month_num, 'Unspecified')\n",
    "    except ValueError:\n",
    "        return 'Unspecified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_anime_data(anime_item):\n",
    "    \"\"\"\n",
    "    This function takes an HTML element representing an anime item and returns a dictionary containing various information about the anime.\n",
    "\n",
    "    ----\n",
    "    Parameters:\n",
    "    - anime_item (bs4.element.Tag): An HTML element representing an anime item.\n",
    "    ----\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the following keys and their corresponding values:\n",
    "        - 'Title': The title of the anime.\n",
    "        - 'Voters': The number of voters for the anime.\n",
    "        - 'Avg Score': The average score of the anime.\n",
    "        - 'Year': The year the anime started.\n",
    "        - 'Season': The season the anime started in.\n",
    "        - 'Studio': The studio that produced the anime.\n",
    "        - 'Genre(s)': A comma-separated string of the genres of the anime.\n",
    "        - 'Media': The type of media the anime is (e.g., TV, movie, OVA).\n",
    "        - 'Status': The status of the anime (e.g., airing, finished, on-hold).\n",
    "        - 'Eps': The number of episodes in the anime.\n",
    "        - 'Duration(min)': The duration of each episode in minutes.\n",
    "    \"\"\"\n",
    "    anime = bs(anime_item.inner_html(), 'html.parser')\n",
    "    return {\n",
    "        'Title': anime.find('span', class_='js-title').text,\n",
    "        'Voters': int(anime.find('span', class_='js-members').text),\n",
    "        'Avg Score': float(anime.find('span', class_='js-score').text),\n",
    "        'Year': anime.find('span', class_='js-start_date').text[:4],\n",
    "        'Season': anime_season(anime.find('span', class_='js-start_date').text[4:6]),\n",
    "        'Studio': [studio.text.strip() for studio in anime.find('div', class_='properties')][1].replace('Studio', ''),\n",
    "        'Genre(s)': ', '.join([data.text.strip() for data in anime.find('div', class_='genres-inner js-genre-inner').select('span')]),\n",
    "        'Media': re.sub(r'[\\W+\\d]', '', [data.text for data in anime.find('div', class_='info').select('span')][0]),\n",
    "        'Status': [data.text for data in anime.find('div', class_='info').select('span')][1],\n",
    "        'Eps': [data.text.split()[0] for data in anime.find('div', class_='info').select('span')][2],\n",
    "        'Duration(min)': [data.text.split()[0] for data in anime.find('div', class_='info').select('span')][-1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playwright_scraper(url: str, last: int) -> list[dict[str, str]]:\n",
    "    \"\"\"\n",
    "    This function uses Playwright to scrape anime data from a specified URL and its subsequent pages.\n",
    "    \n",
    "    -----\n",
    "    Parameters:\n",
    "    - url (str): The URL of the anime list to scrape.\n",
    "    - last (int): The last page number to scrape.\n",
    "    ----\n",
    "    Returns:\n",
    "    - list: A list of dictionaries, where each dictionary represents the scraped data of an anime.\n",
    "    ----\n",
    "    The function first launches a Chromium browser using Playwright and navigates to the specified URL. It then iterates through the pages from 1 to the specified last page, scraping anime data from each page. The scraped data is appended to a container list. Finally, the function closes the browser and returns the container list.\n",
    "    \"\"\"\n",
    "    container = []\n",
    "\n",
    "    with sync_playwright() as p:\n",
    "        try:\n",
    "            browser = p.chromium.launch(headless=True)  # Run in headless mode for efficiency\n",
    "            page = browser.new_page()\n",
    "            page.goto(url)\n",
    "\n",
    "            data_name = page.inner_text('.h1').split()[0]\n",
    "            print(f'Scraping data from {data_name}...')\n",
    "\n",
    "            # Use tqdm to display progress bar for page processing\n",
    "            for page_num in tqdm(range(1, last + 1), desc='Processing Pages', unit='page'):\n",
    "                page_url = f'{url}?page={page_num}'\n",
    "                \n",
    "                try:\n",
    "                    page.goto(page_url, wait_until='networkidle')\n",
    "                    if page.query_selector('.error404'):\n",
    "                        print(f'Page {page_num} of {data_name} does not exist.')\n",
    "                        break\n",
    "\n",
    "                    anime_list = page.query_selector_all('.js-anime-category-producer')\n",
    "                    for anime_item in anime_list:\n",
    "                        container.append(scrape_anime_data(anime_item))\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f'Error processing page {page_num}: {e}')\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error initializing Playwright: {e}')\n",
    "        \n",
    "        finally:\n",
    "            browser.close()\n",
    "\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeler(date: str, data: list[dict[str, str]]) -> None:\n",
    "    \"\"\"\n",
    "    Processes and saves anime data to a CSV file.\n",
    "\n",
    "    -----\n",
    "    Parameters:\n",
    "    - date (str): The date string used to name the CSV file.\n",
    "    - data (List[Dict[str, str]]): A list of dictionaries containing anime data.\n",
    "\n",
    "    -----\n",
    "    The function converts the list of dictionaries to a DataFrame, removes duplicate entries,\n",
    "    and saves the DataFrame to a CSV file in the 'data/processed' directory.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    file_path = f'data/processed/AnimeData_{date}.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f'Data saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# from playwright_scraper import playwright_scraper\n",
    "# from modeler import modeler\n",
    "\n",
    "# Preparation\n",
    "date = datetime.now().strftime('%d%m%y')\n",
    "\n",
    "# EXTRACT AND TRANSFORM\n",
    "url_list = [   \n",
    "    'https://myanimelist.net/anime/genre/1/',  # Action\n",
    "    'https://myanimelist.net/anime/genre/2/',  # Adventure\n",
    "    'https://myanimelist.net/anime/genre/5/',  # Avant Garde\n",
    "    'https://myanimelist.net/anime/genre/4/',  # Comedy\n",
    "    'https://myanimelist.net/anime/genre/8/',  # Drama\n",
    "    'https://myanimelist.net/anime/genre/10/', # Fantasy\n",
    "    'https://myanimelist.net/anime/genre/47/', # Gourmet\n",
    "    'https://myanimelist.net/anime/genre/14/', # Horror\n",
    "    'https://myanimelist.net/anime/genre/7/',  # Mystery\n",
    "    'https://myanimelist.net/anime/genre/22/', # Romance\n",
    "    'https://myanimelist.net/anime/genre/24/', # Sci-fi\n",
    "    'https://myanimelist.net/anime/genre/36/', # Slice-of-life\n",
    "    'https://myanimelist.net/anime/genre/30/', # Sport\n",
    "    'https://myanimelist.net/anime/genre/37/', # Supernatural\n",
    "    'https://myanimelist.net/anime/genre/41/'  # Suspense\n",
    "]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_data = []\n",
    "    for url in url_list:\n",
    "        all_data.extend(playwright_scraper(url, 100))\n",
    "    \n",
    "    modeler(date, all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
